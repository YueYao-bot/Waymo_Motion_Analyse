{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f037793-2e5e-4d37-ac00-d63c5df532c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "\n",
    "import warnings\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768871e7-16c0-4d02-a470-fc590a8e8ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a779bdfc-44ae-4753-a1c0-86e1862e2cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.16.0', '2.8.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979e87a-599f-4a3e-a92d-a594772194aa",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e63022-c375-4203-b6af-9a34a72264fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.int16):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.int64):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, tf.Tensor):\n",
    "            return float(obj)\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04eb8f53-6d49-4a61-8d27-6d3f1c549cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_result(degree, bic_scores, aic_scores, A_list, B_list, losses, best_epochs, lr, optimizer, epochs, batch_size):\n",
    "    # BIC Results\n",
    "    best_bic_deg_idx = np.where(bic_scores == np.amin(bic_scores))[0][0]\n",
    "    best_bic_deg = degrees[best_bic_deg_idx]\n",
    "    bic_best_A = A_list[best_bic_deg_idx]\n",
    "    bic_best_B = B_list[best_bic_deg_idx]\n",
    "    best_bic = bic_scores[best_bic_deg_idx]\n",
    "    \n",
    "    # AIC Results\n",
    "    best_aic_deg_idx = np.where(aic_scores == np.amin(aic_scores))[0][0]\n",
    "    best_aic_deg = degrees[best_aic_deg_idx]\n",
    "    aic_best_A = A_list[best_aic_deg_idx]\n",
    "    aic_best_B = B_list[best_aic_deg_idx]\n",
    "    best_aic = aic_scores[best_aic_deg_idx]\n",
    "    \n",
    "    last_losses = [loss[-1] for loss in losses]\n",
    "    \n",
    "    result = {'degree': degree,\n",
    "          'losses': last_losses,\n",
    "          'A_list': A_list,\n",
    "          'B_list': B_list,\n",
    "              \n",
    "          'bic_scores': bic_scores,\n",
    "          'best_bic': best_bic,\n",
    "          'best_bic_A': bic_best_A,\n",
    "          'best_bic_B': bic_best_B,\n",
    "          'best_bic_deg': best_bic_deg,\n",
    "          'best_bic_deg_idx': best_bic_deg_idx,\n",
    "            \n",
    "          'aic_scores': aic_scores,\n",
    "          'best_aic': best_aic,\n",
    "          'best_aic_A': aic_best_A,\n",
    "          'best_aic_B': aic_best_B,\n",
    "          'best_aic_deg': best_aic_deg,\n",
    "          'best_aic_deg_idx': best_aic_deg_idx,\n",
    "              \n",
    "          'lr': lr,\n",
    "          'optimizer': optimizer,\n",
    "          'epochs': epochs,\n",
    "          'best_epochs': best_epochs,\n",
    "          'batch_size': batch_size\n",
    "        }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1afa69b-4c49-42bd-8e10-ee626c78726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(folder_dir, file_name, result):  \n",
    "    with open(folder_dir + '/' + file_name + '.json', \"w\") as write_file:\n",
    "        json.dump(result, write_file, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77b9937-4a49-47e9-9efa-fb51205d5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(dist, samples):\n",
    "    \"\"\"Calculates the negative log-likelihood for a given distribution\n",
    "    and a data set.\"\"\"\n",
    "    ll = dist.log_prob(samples)\n",
    "    mask_ll = tf.boolean_mask(ll, tf.math.is_finite(ll))\n",
    "    ll = tf.where(tf.math.is_finite(ll), ll, [-1000])\n",
    "    if mask_ll.shape[0] / ll.shape[0] < 0.7:\n",
    "        print('Too much nan in one batch', mask_ll.shape[0], ll.shape[0] )\n",
    "    return -tf.reduce_mean(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc60ba84-a618-499f-a7e7-cdac5248027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def get_loss_and_grads(dist, samples):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(dist.trainable_variables)\n",
    "        loss = nll(dist, samples)\n",
    "    grads = tape.gradient(loss, dist.trainable_variables)\n",
    "\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36e63f7-671f-4123-8050-38d14726dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_distribution(dist, samples, opti, epoch):\n",
    "    loss, grads = get_loss_and_grads(dist, samples)\n",
    "\n",
    "    if tf.math.is_finite(loss) and tf.math.is_finite(grads[1]):\n",
    "        opti.apply_gradients(zip(grads, dist.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd7476a-cde1-468d-8469-49b839c01a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expands a vector to a polynomial design matrix: from a constant to the deg-power\n",
    "def polyBasisScale(x_last, deg):\n",
    "    #Expands a vector to a polynomial design matrix: from a constant to the deg-power\n",
    "    return np.diag(np.squeeze((np.column_stack([x_last**deg for deg in range(0, deg+1)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1b8b03-7055-4f53-8df7-cff925e195a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_basis_function(x, power):\n",
    "    return x ** power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799efee0-d9fe-440d-9072-731f6a2c1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(x, bf, bf_args=None):\n",
    "    if bf_args is None:\n",
    "        return np.concatenate([np.ones(x.shape), bf(x)], axis=1)\n",
    "    else:\n",
    "        return np.array([np.ones(x.shape)] + [bf(x, bf_arg) for bf_arg in bf_args]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47788097-5ffd-40b6-878e-9d4b4cdc4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses, degrees, y_lim = (-50,50)):\n",
    "    fig, ax = plt.subplots()\n",
    "    for i,loss in enumerate(losses):\n",
    "        ax.plot(range(len(loss)), loss, label = str(degrees[i]))\n",
    "    \n",
    "    ax.set_ylim(y_lim)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e921944-cb37-4655-bb92-d10ae8149487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_list_dataset(path_list, outlier_list):\n",
    "    path_list_without_outlier = []\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.abspath(path_list)):\n",
    "        files.sort()\n",
    "        for idx, file in enumerate(tqdm(files)):\n",
    "            if idx in outlier_list:\n",
    "                continue\n",
    "            else:\n",
    "                path_list_without_outlier.append(os.path.join(root, file))\n",
    "\n",
    "    file_list_dataset = tf.data.Dataset.from_tensor_slices(path_list_without_outlier)\n",
    "    \n",
    "    return file_list_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a453cdc2-d447-40b3-aa8d-1b001f538027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_start_indicies_dataset(start_indicies_file, outlier_list):\n",
    "    start_indicies_without_outlier = []\n",
    "\n",
    "    with open(start_indicies_file, \"r\") as read_file:\n",
    "        start_indicies_all = np.array((json.load(read_file)))\n",
    "    \n",
    "    for idx, start_index in enumerate(tqdm(start_indicies_all)):\n",
    "        if idx in outlier_list:\n",
    "            continue\n",
    "        else:\n",
    "            start_indicies_without_outlier.append(start_index)\n",
    "\n",
    "    start_indicies_dataset = tf.data.Dataset.from_tensor_slices(start_indicies_without_outlier)\n",
    "    \n",
    "    return start_indicies_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0d26d-5c2f-438f-8b11-c7a8df8c901c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78126779-f69a-43c8-96a4-745cf186210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    def __init__(self, batch_size, dataset, num_points_in_one_traj):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset  \n",
    "        self.num_points_in_one_traj = num_points_in_one_traj\n",
    "        self.loaded_dataset = None\n",
    "    \n",
    "    def _extract_ego_trajs(self, file_path, start_idx):\n",
    "        file_str = str(file_path.numpy())[2:-1]\n",
    "        ego_trajs_all = []\n",
    "        times_all = []\n",
    "        with open(file_str, \"r\") as read_file:\n",
    "            traj_data = json.load(read_file)\n",
    "            \n",
    "        ego_traj_temp = np.array(traj_data['ego_traj'])[start_idx : start_idx+self.num_points_in_one_traj]\n",
    "        ego_traj_temp = ego_traj_temp[:, :2] - ego_traj_temp[0,:2] # let trajectories start from zero\n",
    "        ego_traj = np.concatenate((ego_traj_temp[:, 0], ego_traj_temp[:, 1]), axis = 0)\n",
    "\n",
    "        times = np.array(traj_data['timestamp'])[start_idx: start_idx+self.num_points_in_one_traj]\n",
    "        times = times - times[0]\n",
    "        \n",
    "        return tf.convert_to_tensor(times, dtype=tf.float32), tf.convert_to_tensor(ego_traj, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    def _load_data(self, file_path, start_idx):\n",
    "        return tf.py_function(self._extract_ego_trajs, [file_path, start_idx], [tf.float32, tf.float32])\n",
    "    \n",
    "    def load_process(self, shuffle = False):\n",
    "        self.loaded_dataset = self.dataset.map(map_func = self._load_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        self.loaded_dataset = self.loaded_dataset.cache()\n",
    "\n",
    "        # Shuffle data and create batches\n",
    "        if shuffle:\n",
    "            self.loaded_dataset = self.loaded_dataset.shuffle(buffer_size=self.loaded_dataset.__len__())\n",
    "        \n",
    "        # Set batch size for dataset\n",
    "        self.loaded_dataset = self.loaded_dataset.batch(self.batch_size)\n",
    "\n",
    "        # Make dataset fetch batches in the background during the training of the model.\n",
    "        self.loaded_dataset = self.loaded_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "    def get_batch(self):\n",
    "        return next(iter(self.loaded_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94f63899-b64e-4e33-ab55-e5230eef71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 120\n",
    "lr = 5e-3\n",
    "\n",
    "original_num_points_in_one_traj = 91\n",
    "num_points_in_one_traj = 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f4895b5-ec71-43df-8c65-547514ac8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487002/487002 [00:00<00:00, 1033247.09it/s]\n",
      "100%|██████████| 487002/487002 [00:00<00:00, 3066291.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(377, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/ego_trajs_not_moving_indicies.json\", \"r\") as read_file:\n",
    "    idx_not_moving = set(json.load(read_file))\n",
    "    \n",
    "with open(\"data/ego_trajs_\" + str(num_points_in_one_traj) + \"_json/ego_trajs_outlier_indicies.json\", \"r\") as read_file:\n",
    "    idx_outlier = set(json.load(read_file))\n",
    "\n",
    "idx_invalid_idx = idx_outlier | idx_not_moving\n",
    "    \n",
    "list_dataset = generate_file_list_dataset('data/ego_trajs_json/', idx_invalid_idx)\n",
    "start_idx_dataset = generate_start_indicies_dataset(\"data/ego_trajs_\" + str(num_points_in_one_traj) + \"_json/ego_trajs_start_point_indicies.json\", idx_invalid_idx)\n",
    "combined_dataset = tf.data.Dataset.zip((list_dataset, start_idx_dataset))\n",
    "\n",
    "dataProcessor = DataProcessor(BATCH_SIZE, combined_dataset, num_points_in_one_traj)\n",
    "dataProcessor.load_process(shuffle = True)\n",
    "\n",
    "print(dataProcessor.loaded_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acc55f77-59b0-4d7c-bdf9-fbd42b7d7e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101302, 101096, 269)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_invalid_idx), len(idx_not_moving), len(idx_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155b5ec-ebc4-4ca4-a8fb-5f91c1b7650c",
   "metadata": {},
   "source": [
    "# Analyse ego_xy with observation noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adaafb-5fa2-491f-8983-e1356d806a5c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76a9634b-ef15-48aa-8688-cd60844c0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mvn(alpha, beta_diag, beta_by_diag, phi_t, num_points):\n",
    "    def mvn_from_alpha_beta(alpha, beta_diag, beta_by_diag, phi_t):      \n",
    "        b_by_diag = tf.eye(num_points_in_one_traj, dtype = tf.float64) * tf.math.softplus(beta_diag) * tf.math.tanh(beta_by_diag)\n",
    "        by_eye = tf.convert_to_tensor([[0,1],[1,0]], dtype=tf.float64)\n",
    "        b_diag = tf.eye(2*num_points, dtype=tf.float64) * tf.math.softplus(beta_diag)\n",
    "        b_kron = b_diag  + tf.experimental.numpy.kron(by_eye, b_by_diag)\n",
    "\n",
    "        cov =   b_kron + (phi_t @ alpha )  @ (tf.transpose(phi_t @ alpha, perm=[0, 2, 1]))\n",
    "        \n",
    "        return tfd.MultivariateNormalTriL(loc=tf.zeros((2* num_points), dtype = tf.float64), scale_tril=tf.linalg.cholesky(cov))\n",
    "    \n",
    "    return tfp.experimental.util.DeferredModule(build_fn=mvn_from_alpha_beta, alpha=alpha, beta_diag=beta_diag, beta_by_diag=beta_by_diag, phi_t = phi_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de8aaca8-93ba-488b-947e-1033959dd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(alpha, beta_diag, beta_by_diag, opti, data_loader, epochs = 100, tf_summary_writer = None, verbose = False, early_stop = True):\n",
    "    model_losses = []\n",
    "    best_alpha = None\n",
    "    best_beta_diag, best_beta_by_diag = None, None\n",
    "    best_epoch_loss = np.inf\n",
    "    best_epoch = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        batch_losses = []\n",
    "        for timestamp_samples, trajectories_samples in data_loader:\n",
    "\n",
    "            phi_t_batch = expand(timestamp_samples/t_scale_factor, bf=polynomial_basis_function, bf_args=range(1, deg+1)).transpose((1, 0, 2))\n",
    "            phi_t_kron = np.kron(np.eye(2), phi_t_batch[:, :, 1:])\n",
    "            \n",
    "            phi_t_kron = tf.cast(phi_t_kron, dtype = tf.float64)\n",
    "            trajectories_samples = tf.cast(trajectories_samples, dtype = tf.float64)\n",
    "            \n",
    "            mvn_test = build_mvn(alpha=alpha, beta_diag=beta_diag, beta_by_diag=beta_by_diag, phi_t = phi_t_kron, num_points = num_points_in_one_traj)\n",
    "\n",
    "            batch_loss = fit_distribution(mvn_test, trajectories_samples, optimizer,epoch)\n",
    "            batch_losses.append(batch_loss)\n",
    "            \n",
    "            tf.keras.backend.clear_session() # clear the initiated model in this loop\n",
    "        gc.collect()\n",
    "            \n",
    "        assert not tf.math.is_nan(np.mean(batch_losses))\n",
    "        \n",
    "        epoch_loss = np.mean(batch_losses)\n",
    "        \n",
    "        if epoch_loss < best_epoch_loss:\n",
    "            best_epoch_loss = epoch_loss\n",
    "            best_epoch = epoch\n",
    "            best_alpha, best_beta_diag, best_beta_by_diag = deepcopy(alpha), deepcopy(beta_diag), deepcopy(beta_by_diag)\n",
    "        \n",
    "        model_losses.append(epoch_loss)\n",
    "        \n",
    "        if tf_summary_writer:\n",
    "            with tf_summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', np.mean(batch_losses), step=epoch)\n",
    "        \n",
    "        # Early stop if epoch loss doesn't decrease for more then 20 epochs \n",
    "        if early_stop and epoch - best_epoch >=20:\n",
    "            print('Early Stop at ' + str(epoch) + '(' + str(best_epoch) + ')' + ' epoch')\n",
    "            break\n",
    "        \n",
    "        if(epoch %10 == 0 and verbose):\n",
    "        #    A_scale_mat = polyBasisScale(t_scale_factor, deg)\n",
    "        #    A_scale_mat = A_scale_mat[1:, 1:]\n",
    "        #    A_est = np.linalg.inv(np.kron(np.eye(2), A_scale_mat)) @ A.numpy()\n",
    "        #    A_est = A_est @ A_est.T\n",
    "            print('Epoch ', epoch, ', Loss: ', model_losses[-1])\n",
    "        #    print(tf.math.softplus(B_diag), tf.math.softplus(B_diag) * tf.math.tanh(B_by_diag))\n",
    "        #    print(np.diag(A_est))\n",
    "        #    #print('Rank: ', np.linalg.matrix_rank(mvn_test.covariance()))\n",
    "        \n",
    "    return model_losses, best_epoch_loss, best_epoch, best_alpha, best_beta_diag, best_beta_by_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58071d68-14a7-4d3d-a27c-1985682ffcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AIC_BIC(nll, deg, num_points):\n",
    "    # Compute bayesian information criterion\n",
    "    degree_of_freedom = 2 + (2*deg)*(2*(deg)+1) / 2\n",
    "    bic_score = nll + 0.5 * np.log(num_points) * degree_of_freedom\n",
    "    \n",
    "    # Compute Akaike information criterion\n",
    "    aic_score = nll + degree_of_freedom\n",
    "    \n",
    "    return aic_score, bic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66ef63-d97e-406f-bcb7-75266f80fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig deg  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/120 [11:00<21:50:18, 660.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , Loss:  18443.468079801176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11/120 [37:11<4:53:44, 161.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 , Loss:  935.0098647285442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 21/120 [1:03:38<4:22:40, 159.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 , Loss:  594.5401905424935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 31/120 [1:29:57<3:53:41, 157.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30 , Loss:  499.4547188344896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 41/120 [1:56:16<3:28:38, 158.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 , Loss:  471.26203073412336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 51/120 [2:23:24<3:03:06, 159.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 , Loss:  461.64976343222406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 61/120 [2:49:40<2:35:35, 158.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60 , Loss:  458.2074061725571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 71/120 [3:15:53<2:08:43, 157.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70 , Loss:  457.06163584890027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 81/120 [3:42:11<1:42:00, 156.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80 , Loss:  456.75301300658174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 91/120 [4:08:32<1:16:17, 157.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90 , Loss:  456.7149070325447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 101/120 [4:34:44<49:34, 156.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100 , Loss:  456.7082156722197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 111/120 [5:00:59<23:41, 157.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  110 , Loss:  456.70738257564284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [5:24:44<00:00, 162.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 456.71545631389705 467.97618220748666 461.69903344119456\n",
      "Trainig deg  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/120 [02:40<5:18:08, 160.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , Loss:  7168.927200576608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11/120 [29:14<4:48:48, 158.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 , Loss:  721.3266166158932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 21/120 [55:58<4:23:39, 159.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 , Loss:  414.0649779300693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 31/120 [1:22:30<3:55:14, 158.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30 , Loss:  227.21568436152808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 41/120 [1:49:14<3:31:07, 160.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 , Loss:  197.5267463898139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 51/120 [2:15:52<3:04:04, 160.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 , Loss:  187.6893008463835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 61/120 [2:42:23<2:35:38, 158.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60 , Loss:  184.568940211015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 71/120 [3:09:09<2:11:18, 160.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70 , Loss:  183.72660690581802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 79/120 [3:30:36<1:49:57, 160.91s/it]"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "best_epoch_losses = []\n",
    "best_epochs = []\n",
    "bic_scores = []\n",
    "aic_scores = []\n",
    "A_list, B_list = [], []\n",
    "lr_schedules_ser = []\n",
    "optimizers_ser = []\n",
    "log_root_dir = 'logs/gradient_tape/ego_xy' + str(num_points_in_one_traj) + '_new'\n",
    "t_scale_factor = (num_points_in_one_traj-1) / 10 # The time duration of one trajectory\n",
    "nan_batches = []\n",
    "degrees = np.linspace(1, 8, 8, dtype=np.int16) # analyse polynomials from degree 1 to 8\n",
    "#degrees = [8]\n",
    "for i_d, deg in enumerate(degrees):\n",
    "    print('Trainig deg ',deg)\n",
    "    \n",
    "    if deg <= 3:\n",
    "        boundaries = [dataProcessor.loaded_dataset.__len__().numpy()*30, dataProcessor.loaded_dataset.__len__().numpy()*70]\n",
    "        values = [4e-3, 5e-4, 1e-4]\n",
    "    #elif deg == 5:\n",
    "    #    boundaries = [dataProcessor.loaded_dataset.__len__().numpy()*15, dataProcessor.loaded_dataset.__len__().numpy()*70]\n",
    "    #    values = [1e-3, 1e-4, 5e-5]\n",
    "    else:\n",
    "        boundaries = [dataProcessor.loaded_dataset.__len__().numpy()*15, dataProcessor.loaded_dataset.__len__().numpy()*70]\n",
    "        values = [1e-3, 1e-4, 5e-5]\n",
    "    \n",
    "    #oundaries = [dataProcessor.loaded_dataset.__len__().numpy()*20, dataProcessor.loaded_dataset.__len__().numpy()*70]\n",
    "    #values = [1e-3, 1e-3, 1e-3]\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)   \n",
    "    \n",
    "    lr_schedules_ser.append(tf.keras.optimizers.schedules.serialize(lr_schedule))\n",
    "    optimizers_ser.append(tf.keras.optimizers.serialize(optimizer))\n",
    "    \n",
    "    A = tf.Variable(np.random.randn(2*(deg), 2*(deg)) * 1e-1 , dtype=tf.float64, name='alpha') # Model uncertainty\n",
    "    B_diag = tf.Variable(np.random.randn(1) * 1e-1, dtype=tf.float64, name='beta_diag') # Log of Observation uncertainty\n",
    "    B_by_diag =  tf.Variable(np.random.randn(1) * 1e-1, dtype=tf.float64, name='beta_by_diag')\n",
    "\n",
    "    \n",
    "    train_log_dir = log_root_dir + '/deg_' + str(deg)\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_dir)  \n",
    "   \n",
    "    model_losses, best_epoch_loss, best_epoch, best_alpha, best_beta_diag, best_beta_by_diag = train(alpha=A, beta_diag=B_diag, beta_by_diag=B_by_diag, opti=optimizer, \n",
    "                                                     epochs = EPOCHS, data_loader=dataProcessor.loaded_dataset, tf_summary_writer = train_summary_writer, verbose = True, early_stop=False)\n",
    "            \n",
    "    # Add model loss\n",
    "    losses.append(model_losses)\n",
    "    best_epoch_losses.append([best_epoch_loss])\n",
    "    \n",
    "    # store the best epoch\n",
    "    best_epochs.append(best_epoch)\n",
    "    \n",
    "    # Compute the AIC and BIC score\n",
    "    aic_score, bic_score = compute_AIC_BIC(nll = best_epoch_loss, deg = deg, num_points = num_points_in_one_traj)\n",
    "\n",
    "    bic_scores.append(bic_score)\n",
    "    aic_scores.append(aic_score)\n",
    "    \n",
    "    # Compute the model uncertainty, A_unscaled = np.linalg.inv(scale_mat) @ A_scaled\n",
    "    A_scale_mat = polyBasisScale(t_scale_factor, deg)\n",
    "    A_scale_mat = A_scale_mat[1:, 1:]\n",
    "    A_est = np.linalg.inv(np.kron(np.eye(2), A_scale_mat)) @ best_alpha.numpy()\n",
    "    A_est = A_est @ A_est.T\n",
    "    A_list.append(A_est)\n",
    "    \n",
    "    # Compute the observation uncertainty, B_cov = tf.eye(num_points_in_one_traj) * tf.math.softplus(B)\n",
    "    B_est = {'B_diag': (tf.math.softplus(best_beta_diag)).numpy(), \n",
    "             'B_by_diag': (tf.math.softplus(best_beta_diag) * tf.math.tanh(best_beta_by_diag)).numpy()}\n",
    "    B_list.append(B_est)\n",
    "    print(deg, model_losses[-1], bic_score, aic_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a60c6-bbe8-4b9d-bdc3-9c9cad925f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = calculate_result(degrees, bic_scores, aic_scores, A_list, B_list, best_epoch_losses, best_epochs, lr, None, EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19bd5c-7b07-4cfd-acce-aa87a0ba29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plot_losses(losses, degrees = degrees, y_lim=[-400, 100])\n",
    "fig.savefig('imgs/ego_' + str(num_points_in_one_traj) + '_new.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8f8a88d-55c4-43f6-8a86-85f54da3e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plot_losses([model_losses], degrees = degrees, y_lim=[-300, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce08d82a-9157-4610-9542-3d4ec62435ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.14522466e+01, -2.73942286e-01, -4.10133558e-02,\n",
       "         5.76802892e-04,  2.60812928e-04,  1.00650900e-08,\n",
       "        -1.10050386e-06, -1.51519316e+00,  3.36503576e-02,\n",
       "         5.09021338e-04, -5.24760282e-04,  2.66848690e-05,\n",
       "         1.53142460e-06, -1.08119344e-07],\n",
       "       [-2.73942286e-01,  1.99848203e-01, -4.33435507e-02,\n",
       "         6.73612048e-03, -4.71637003e-04, -2.96163099e-06,\n",
       "         1.31961829e-06, -4.55225715e-02,  8.14936940e-04,\n",
       "         1.78261024e-03, -2.12300858e-04,  1.11887377e-05,\n",
       "        -1.18823473e-06,  8.35346261e-08],\n",
       "       [-4.10133558e-02, -4.33435507e-02,  2.83199940e-02,\n",
       "        -6.12331564e-03,  5.51016605e-04, -1.25400125e-05,\n",
       "        -5.27205369e-07, -1.24517638e-03, -2.91873655e-03,\n",
       "         6.79339345e-04, -8.18916865e-05,  3.86088155e-06,\n",
       "         2.49962880e-07, -2.63205034e-08],\n",
       "       [ 5.76802892e-04,  6.73612048e-03, -6.12331564e-03,\n",
       "         1.77385703e-03, -2.27150042e-04,  1.26769281e-05,\n",
       "        -2.19576213e-07,  3.95464843e-04,  6.68537662e-04,\n",
       "        -4.09747847e-04,  9.54299016e-05, -1.06340892e-05,\n",
       "         5.46732473e-07, -9.23382338e-09],\n",
       "       [ 2.60812928e-04, -4.71637003e-04,  5.51016605e-04,\n",
       "        -2.27150042e-04,  4.17567436e-05, -3.57616383e-06,\n",
       "         1.16831163e-07, -1.16228937e-06, -8.46698991e-05,\n",
       "         7.47539965e-05, -2.36096898e-05,  3.41823648e-06,\n",
       "        -2.31620808e-07,  5.85452663e-09],\n",
       "       [ 1.00650900e-08, -2.96163099e-06, -1.25400125e-05,\n",
       "         1.26769281e-05, -3.57616383e-06,  4.05712957e-07,\n",
       "        -1.63841536e-08, -3.19329944e-06,  6.13281019e-06,\n",
       "        -6.08558046e-06,  2.38080376e-06, -4.08230020e-07,\n",
       "         3.17551646e-08, -9.11830740e-10],\n",
       "       [-1.10050386e-06,  1.31961829e-06, -5.27205369e-07,\n",
       "        -2.19576213e-07,  1.16831163e-07, -1.63841536e-08,\n",
       "         7.42070843e-10,  1.74949857e-07, -1.98367452e-07,\n",
       "         1.90787221e-07, -8.76410590e-08,  1.69771779e-08,\n",
       "        -1.44584910e-09,  4.47611984e-11],\n",
       "       [-1.51519316e+00, -4.55225715e-02, -1.24517638e-03,\n",
       "         3.95464843e-04, -1.16228937e-06, -3.19329944e-06,\n",
       "         1.74949857e-07,  4.01367958e+01, -3.75695617e-01,\n",
       "        -4.84388887e-02,  1.41223810e-03,  1.75118812e-04,\n",
       "         1.07990988e-05, -1.57328586e-06],\n",
       "       [ 3.36503576e-02,  8.14936940e-04, -2.91873655e-03,\n",
       "         6.68537662e-04, -8.46698991e-05,  6.13281019e-06,\n",
       "        -1.98367452e-07, -3.75695617e-01,  2.24377951e-01,\n",
       "        -4.90114570e-02,  7.96924482e-03, -6.14847798e-04,\n",
       "         3.87246096e-06,  1.25432195e-06],\n",
       "       [ 5.09021338e-04,  1.78261024e-03,  6.79339345e-04,\n",
       "        -4.09747847e-04,  7.47539965e-05, -6.08558046e-06,\n",
       "         1.90787221e-07, -4.84388887e-02, -4.90114570e-02,\n",
       "         3.24419792e-02, -7.20142639e-03,  6.83245367e-04,\n",
       "        -1.97340810e-05, -4.05213737e-07],\n",
       "       [-5.24760282e-04, -2.12300858e-04, -8.18916865e-05,\n",
       "         9.54299016e-05, -2.36096898e-05,  2.38080376e-06,\n",
       "        -8.76410590e-08,  1.41223810e-03,  7.96924482e-03,\n",
       "        -7.20142639e-03,  2.09628737e-03, -2.71266792e-04,\n",
       "         1.54384013e-05, -2.81315477e-07],\n",
       "       [ 2.66848690e-05,  1.11887377e-05,  3.86088155e-06,\n",
       "        -1.06340892e-05,  3.41823648e-06, -4.08230020e-07,\n",
       "         1.69771779e-08,  1.75118812e-04, -6.14847798e-04,\n",
       "         6.83245367e-04, -2.71266792e-04,  4.85994543e-05,\n",
       "        -4.07810600e-06,  1.30926388e-07],\n",
       "       [ 1.53142460e-06, -1.18823473e-06,  2.49962880e-07,\n",
       "         5.46732473e-07, -2.31620808e-07,  3.17551646e-08,\n",
       "        -1.44584910e-09,  1.07990988e-05,  3.87246096e-06,\n",
       "        -1.97340810e-05,  1.54384013e-05, -4.07810600e-06,\n",
       "         4.49396984e-07, -1.78583662e-08],\n",
       "       [-1.08119344e-07,  8.35346261e-08, -2.63205034e-08,\n",
       "        -9.23382338e-09,  5.85452663e-09, -9.11830740e-10,\n",
       "         4.47611984e-11, -1.57328586e-06,  1.25432195e-06,\n",
       "        -4.05213737e-07, -2.81315477e-07,  1.30926388e-07,\n",
       "        -1.78583662e-08,  7.99823855e-10]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['best_aic_A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cabc5eb2-b979-452a-8ac2-7535785138be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_diag': array([0.00026802]), 'B_by_diag': array([-3.16223622e-06])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['best_aic_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68f64f-e682-4c66-aa5b-dfdbc0336d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(folder_dir =log_root_dir, file_name='result_summary', result=result)\n",
    "with open(log_root_dir + '/' + 'lr_schedules' + '.json', \"w\") as write_file:\n",
    "    json.dump(lr_schedules_ser, write_file, cls=NumpyEncoder)\n",
    "with open(log_root_dir + '/' + 'optimizers' + '.json', \"w\") as write_file:\n",
    "    json.dump(optimizers_ser, write_file, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19940e-7ff0-482e-91b0-8db194375700",
   "metadata": {},
   "source": [
    "# Dummy Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81580e57-143c-4507-887c-996a2135eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_one_traj = 21\n",
    "deg_to_change = 1\n",
    "idx_to_change = deg_to_change-1\n",
    "with open('logs/gradient_tape/ego_xy' + str(num_points_in_one_traj) + '/result_summary.json', \"r\") as read_file:\n",
    "    result_old = json.load(read_file)\n",
    "          \n",
    "with open('logs/gradient_tape/ego_xy' + str(num_points_in_one_traj) + '_only_' + str(deg_to_change) + 'th/result_summary.json', \"r\") as read_file:\n",
    "    result_sub = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44a52a28-134d-4f3d-a5b7-342db327d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_old['losses'][idx_to_change] = result_sub['losses'][0]\n",
    "result_old['A_list'][idx_to_change] = result_sub['A_list'][0]\n",
    "result_old['B_list'][idx_to_change] = result_sub['B_list'][0]\n",
    "\n",
    "result_old['lr'][idx_to_change] = result_sub['lr'][0]\n",
    "result_old['optimizer'][idx_to_change] = result_sub['optimizer'][0]\n",
    "\n",
    "result_old['bic_scores'][idx_to_change] = result_sub['bic_scores'][0]\n",
    "best_bic_deg_idx = np.where(result_old['bic_scores'] == np.amin(result_old['bic_scores']))[0][0]\n",
    "result_old['best_bic'] = result_old['bic_scores'][best_bic_deg_idx]\n",
    "result_old['best_bic_A'] = result_old['A_list'][best_bic_deg_idx]\n",
    "result_old['best_bic_B'] = result_old['B_list'][best_bic_deg_idx]\n",
    "result_old['best_bic_deg'] = result_old['degree'][best_bic_deg_idx]\n",
    "result_old['best_bic_deg_idx'] = best_bic_deg_idx\n",
    "\n",
    "\n",
    "result_old['aic_scores'][idx_to_change] = result_sub['aic_scores'][0]\n",
    "best_aic_deg_idx = np.where(result_old['aic_scores'] == np.amin(result_old['aic_scores']))[0][0]\n",
    "result_old['best_aic'] = result_old['aic_scores'][best_aic_deg_idx]\n",
    "result_old['best_aic_A'] = result_old['A_list'][best_aic_deg_idx]\n",
    "result_old['best_aic_B'] = result_old['B_list'][best_aic_deg_idx]\n",
    "result_old['best_aic_deg'] = result_old['degree'][best_aic_deg_idx]\n",
    "result_old['best_aic_deg_idx'] = best_aic_deg_idx\n",
    "\n",
    "with open('logs/gradient_tape/ego_xy' + str(num_points_in_one_traj) + '/result_summary_new.json', \"w\") as write_file:\n",
    "    json.dump(result_old, write_file, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21d813-c785-408a-8248-547388ff3e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p38)",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
